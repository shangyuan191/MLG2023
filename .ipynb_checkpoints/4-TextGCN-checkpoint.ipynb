{"cells":[{"cell_type":"markdown","id":"65c49127","metadata":{"id":"65c49127"},"source":["# Text classification with GNN: TextGCN\n","In this tutorial, we will go through the details of how to implement the TextGCN model proposed by Liang et al. 2019. <br>\n","\n","From the previous lectures, we have seen how the GNN models work to extract graph and node representations in unsupervised and supervised learning tasks.<br>\n","Here we demonstrate how GNNs could be applied on learning document embeddings.\n","Text GCN is a model which allows us to use a graph neural network for text classification where the type of network is convolutional. The below figure is a representation of the adaptation of convolutional graphs using the Text GCN.\n","\n","![](https://149695847.v2.pressablecdn.com/wp-content/uploads/2021/11/image-15-1024x412.png)\n"]},{"cell_type":"markdown","id":"23fb065b","metadata":{"id":"23fb065b"},"source":["The model in Text GCN takes the input in the form of an identity matrix so that every word can be represented as the one-hot vector. To generate the TF-IDF (term frequency-inverse document frequency) of the word in the document the model generates the edges among nodes based on the word occurrence in the global corpus. Like in the traditional way in TF-IDF the term frequency represents the number of occurrences of the word in the document.to gather the co-occurrence statistics the model supplies a fixed size window on the documents in the corpus and the sliding of the window makes the global word co-occurrence information useful for prediction and classification. \n","\n","Mathematically the weight of an edge between node i and node j is defined as \n","\n","\n","![](https://149695847.v2.pressablecdn.com/wp-content/uploads/2021/11/image-16.png)\n","\n","We summarize the pipeline for using TextGCN to perform text classification as follows:\n","\n","1. **Preparation of text data**: cleaning data, removing stopwords, train-test split.\n","2. **Preparation of text graph**: buid a heterogenous graph based on the aforementioned formula.\n","3. **Model training**: create a GCN model with takes the text graph, node feature and edge weight to learn document embeddings."]},{"cell_type":"markdown","id":"17945f3c","metadata":{"id":"17945f3c"},"source":["## Data preparation"]},{"cell_type":"code","execution_count":1,"id":"f5c09b48","metadata":{"id":"f5c09b48","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663396077108,"user_tz":-480,"elapsed":21459,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"c7337c0a-f415-4699-ade6-e91d72588d6a"},"outputs":[{"output_type":"stream","name":"stdout","text":["1.12.1+cu113\n","\u001b[K     |████████████████████████████████| 7.9 MB 7.5 MB/s \n","\u001b[K     |████████████████████████████████| 3.5 MB 7.9 MB/s \n","\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 2.4 MB 8.7 MB/s \n","\u001b[?25h"]}],"source":["# install packages\n","import os\n","import torch\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)\n","\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","!pip install -q torch-cluster -f https://data.pyg.org/whl/torch-${TORCH}.html"]},{"cell_type":"code","execution_count":2,"id":"ea01a9fb","metadata":{"id":"ea01a9fb","executionInfo":{"status":"ok","timestamp":1663396078131,"user_tz":-480,"elapsed":1040,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}}},"outputs":[],"source":["# import packages\n","import random\n","import numpy as np\n","import pickle as pkl\n","import torch\n","import scipy.sparse as sp\n","import pandas as pd \n","\n","from math import log\n","from collections import defaultdict\n","from torch_geometric.data import Data\n","from sklearn.preprocessing import LabelEncoder\n","from tqdm.auto import tqdm"]},{"cell_type":"code","execution_count":3,"id":"fb7914ef","metadata":{"id":"fb7914ef","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663396078132,"user_tz":-480,"elapsed":6,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"adf55e49-0ca4-40a7-f33c-b4e1befcfc12"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data()"]},"metadata":{},"execution_count":3}],"source":["# create a empty Data object\n","pyg_data = Data()\n","pyg_data"]},{"cell_type":"code","execution_count":4,"id":"2ec041b3","metadata":{"id":"2ec041b3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663396096849,"user_tz":-480,"elapsed":18721,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"edb727f1-d061-4dbc-ce7e-4f4dfab29aa8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'text_gcn.pytorch'...\n","remote: Enumerating objects: 80, done.\u001b[K\n","remote: Counting objects: 100% (21/21), done.\u001b[K\n","remote: Compressing objects: 100% (13/13), done.\u001b[K\n","remote: Total 80 (delta 12), reused 8 (delta 8), pack-reused 59\u001b[K\n","Unpacking objects: 100% (80/80), done.\n","Checking out files: 100% (39/39), done.\n","/content/text_gcn.pytorch/preprocess\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","{'these', 'be', \"didn't\", 'once', 'in', 'can', 'have', 'whom', 'both', 'no', 'so', 'itself', 'very', 'while', \"hasn't\", 'before', 'yourselves', 'at', 'because', \"should've\", \"you'll\", 'shan', 'about', 'were', \"weren't\", 'our', 'from', 'here', 'just', \"you'd\", 'above', \"doesn't\", 'has', 'him', 'any', 'their', 'why', \"you've\", 'an', 'aren', 'wouldn', 'yours', 'you', 'how', 'a', 'haven', 'been', 'into', 'who', 'for', 'his', 'and', 'below', 'most', 'hers', 'mustn', \"won't\", \"shouldn't\", 'during', 'herself', 'theirs', 'did', 'each', 'your', 'when', 'yourself', 'didn', \"mustn't\", 'myself', 'he', \"couldn't\", 'they', 'is', 'other', 'having', 'nor', 'doing', 'was', 've', \"haven't\", 'there', \"shan't\", 'own', 'shouldn', 'up', 'off', 'too', 'but', 'm', \"aren't\", 'what', 'those', 'ourselves', 'if', 'which', 'doesn', 'the', \"isn't\", 'hasn', 'further', 'that', 'again', 'my', 'll', \"it's\", 'them', 'do', 'weren', 'on', 'out', 'should', 'few', 'not', 'with', 'all', 'isn', 't', 'then', 'themselves', 'some', 'will', 'won', 'hadn', \"don't\", 'down', 'ma', 'me', 'had', 'mightn', \"she's\", 's', \"hadn't\", 'are', 'as', 'over', 'being', \"that'll\", 'more', 'than', \"mightn't\", 'to', 'couldn', 'needn', 'only', 'don', 'through', 'ours', 'it', 're', 'where', \"you're\", 'am', 'of', 'o', 'we', 'her', 'under', 'd', 'himself', 'i', 'same', \"wouldn't\", 'she', 'y', 'after', 'ain', \"wasn't\", 'between', 'wasn', 'its', 'against', 'now', 'such', 'by', 'this', 'does', \"needn't\", 'until', 'or'}\n","Min_len : 4\n","Max_len : 520\n","Average_len : 65.72126661454261\n","/content\n"]}],"source":["# download data\n","! git clone https://github.com/iworldtong/text_gcn.pytorch.git\n","%cd text_gcn.pytorch/preprocess/\n","! python remove_words.py R8\n","%cd ../../"]},{"cell_type":"code","execution_count":5,"id":"2c23c4f6","metadata":{"id":"2c23c4f6","executionInfo":{"status":"ok","timestamp":1663396096849,"user_tz":-480,"elapsed":25,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}}},"outputs":[],"source":["dataset = \"R8\"\n","\n","# list for data\n","train_data = []\n","test_data = []\n","\n","with open('text_gcn.pytorch/data/' + dataset + '.txt', 'r') as f:\n","    lines = f.readlines()\n","    for line in lines:\n","        temp = line.strip().split(\"\\t\") # temp: [docID, Train/Test, target_class]\n","        if \"train\" in temp:\n","            train_data.append(temp)\n","        elif \"test\" in temp:\n","            test_data.append(temp)"]},{"cell_type":"code","execution_count":6,"id":"128cef77","metadata":{"id":"128cef77","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663396096850,"user_tz":-480,"elapsed":24,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"bb960c94-7c19-431c-9b6c-4150782ddf48"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['0', 'train', 'earn'], ['1', 'train', 'acq'], ['2', 'train', 'earn']]"]},"metadata":{},"execution_count":6}],"source":["train_data[:3]"]},{"cell_type":"code","execution_count":7,"id":"bf4d301d","metadata":{"id":"bf4d301d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663396096850,"user_tz":-480,"elapsed":21,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"66e03fde-cd7c-4ec6-caaa-f7bd9bd129b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of documents 7674\n","Number of classes: 8\n"]}],"source":["# unpack train data\n","train_ids, _, train_target = zip(*train_data)\n","train_ids = np.array(list(map(int,train_ids)))\n","train_target = list(train_target)\n","\n","# unpack test data\n","test_ids, _, test_target = zip(*test_data)\n","test_ids = np.array(list(map(int,test_ids)))\n","test_target = list(test_target)\n","\n","# all ids\n","document_ids = np.append(train_ids,test_ids)\n","\n","# handling labels\n","label_list = train_target + test_target\n","enc = LabelEncoder()\n","label_list = enc.fit_transform(label_list)\n","train_target = enc.transform(train_target)\n","test_target = enc.transform(test_target)\n","\n","num_classes = len(enc.classes_)\n","print(\"Number of documents\",len(document_ids))\n","print(\"Number of classes:\",num_classes)\n","\n","# sizes\n","train_size = len(train_ids)\n","val_size = int(0.1 * train_size)\n","real_train_size = train_size - val_size\n","test_size = len(test_ids)"]},{"cell_type":"code","execution_count":8,"id":"28e2e869","metadata":{"id":"28e2e869","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663396096850,"user_tz":-480,"elapsed":20,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"9aa15532-4bdf-4a77-ef8e-b2e63c5ddec3"},"outputs":[{"output_type":"stream","name":"stdout","text":["champion products approves stock split champion products inc said board directors approved two one stock split common shares shareholders record april company also said board voted recommend shareholders annual meeting april increase authorized capital stock five mln mln shares reuter\n"]}],"source":["# load document content from cleaned data\n","doc_content_list = []\n","with open('text_gcn.pytorch/data/corpus/' + dataset + '.clean.txt', 'r') as f:\n","    lines = f.readlines()\n","    for line in lines:\n","        doc_content_list.append(line.strip())\n","print(doc_content_list[0])"]},{"cell_type":"markdown","id":"94dabde9","metadata":{"id":"94dabde9"},"source":["## Build vocabulary\n","To create the text graph, we need to first calculate the TF and IDF as the edge weight."]},{"cell_type":"code","execution_count":9,"id":"0309c076","metadata":{"id":"0309c076","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663396096850,"user_tz":-480,"elapsed":18,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"ea4b00cc-755c-42f0-ad40-52f306ae89c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Vocaulary size: 7688\n"]}],"source":["# build vocabulary set and calculate word frequency\n","word_freq = {}\n","word_set = set()\n","for doc_words in doc_content_list:\n","    words = doc_words.split()\n","    for word in words:\n","        word_set.add(word)\n","        if word in word_freq:\n","            word_freq[word] += 1\n","        else:\n","            word_freq[word] = 1\n","\n","vocab = list(word_set)\n","vocab_size = len(vocab)\n","print(\"Vocaulary size:\",vocab_size)"]},{"cell_type":"code","execution_count":10,"id":"8b301cc6","metadata":{"id":"8b301cc6","executionInfo":{"status":"ok","timestamp":1663396097295,"user_tz":-480,"elapsed":462,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}}},"outputs":[],"source":["# create document-word dictionary\n","word_doc_list = defaultdict(set)\n","\n","for i in range(len(doc_content_list)):\n","    doc_words = doc_content_list[i]\n","    words = doc_words.split()\n","    for word in words:\n","            word_doc_list[word].add(i)\n","\n","# calculate term frequency\n","word_doc_freq = {}\n","for word, doc_list in word_doc_list.items():\n","    word_doc_freq[word] = len(doc_list)\n","    \n","# word-index mapping\n","word_id_map = {}\n","for i in range(vocab_size):\n","    word_id_map[vocab[i]] = i\n","\n","vocab_str = '\\n'.join(vocab)"]},{"cell_type":"markdown","id":"fc9386e4","metadata":{"id":"fc9386e4"},"source":["# Heterogeneous graph construction\n","There are two types of node in the text graph: **Document node** and **Word node**.<br>\n","* Document-word edge: if a word appears in the document, create an edge between them. TF-IDF is used as the edge weight.\n","* Word-word edge: capturing the co-occurrence of words if they appeared in same document. PMI is used as edge weight.\n","\n","![](https://149695847.v2.pressablecdn.com/wp-content/uploads/2021/11/image-16.png)"]},{"cell_type":"code","execution_count":11,"id":"8977410a","metadata":{"id":"8977410a","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["0a82691357244784b013f12170604a65","b1803b8d62a44f1697135918c073a1c9","a45319a11afa471eb444b1aaeca98082","c88174bbd9a54ae3887f9a44c9fc00b1","497d2a652f4348fb89399f28b10aee85","1eee6e4b846944928a9463141fd3cc8f","c9cba94290e84baea9563b4c207f0b59","f45a57d5a7c142e48f178b02780a9d3d","f952c8d4c3054bd8a1dc26492935e90f","991f6fa9476741809b4ccf5be46a681b","87be341abfdc4b01a9dc1da289eda1df"]},"executionInfo":{"status":"ok","timestamp":1663396184959,"user_tz":-480,"elapsed":87666,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"cfda050c-5909-4267-a496-25bc34ea19ae"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/400703 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a82691357244784b013f12170604a65"}},"metadata":{}}],"source":["# word co-occurence with context windows\n","# store words in the same window\n","window_size = 15\n","windows = []\n","\n","for doc_words in doc_content_list:\n","    words = doc_words.split()\n","    length = len(words)\n","    if length <= window_size:\n","        windows.append(words)\n","    else:\n","        for j in range(length - window_size + 1):\n","            window = words[j: j + window_size]\n","            windows.append(window)\n","\n","# calculate p(word)\n","word_window_freq = {}\n","for window in windows:\n","    appeared = set()\n","    for i in range(len(window)):\n","        word = window[i]\n","        # continue if the frequency of the word has been calculated\n","        if word in appeared:\n","            continue\n","        if word in word_window_freq:\n","            word_window_freq[word] += 1\n","        else:\n","            word_window_freq[word] = 1\n","        appeared.add(word)\n","\n","# calculate co-occurrence frequency (i.e., p(i,j))\n","word_pair_count = {}\n","for window in tqdm(windows):\n","    for i in range(1, len(window)):\n","        for j in range(0, i):\n","            word_i = window[i]\n","            word_i_id = word_id_map[word_i]\n","            word_j = window[j]\n","            word_j_id = word_id_map[word_j]\n","            if word_i_id == word_j_id:\n","                continue\n","            word_pair_str = str(word_i_id) + ',' + str(word_j_id)\n","            if word_pair_str in word_pair_count:\n","                word_pair_count[word_pair_str] += 1\n","            else:\n","                word_pair_count[word_pair_str] = 1\n","            # two orders\n","            word_pair_str = str(word_j_id) + ',' + str(word_i_id)\n","            if word_pair_str in word_pair_count:\n","                word_pair_count[word_pair_str] += 1\n","            else:\n","                word_pair_count[word_pair_str] = 1"]},{"cell_type":"markdown","id":"42ac47ff","metadata":{"id":"42ac47ff"},"source":["## Creating wor-word edges and calculate edge weights"]},{"cell_type":"code","execution_count":12,"id":"cc67b061","metadata":{"id":"cc67b061","executionInfo":{"status":"ok","timestamp":1663396190878,"user_tz":-480,"elapsed":5926,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}}},"outputs":[],"source":["row = []\n","col = []\n","weight = []\n","\n","# pmi as weights\n","\n","num_window = len(windows)\n","\n","for key in word_pair_count:\n","    temp = key.split(',')\n","    i = int(temp[0])\n","    j = int(temp[1])\n","    count = word_pair_count[key]\n","    word_freq_i = word_window_freq[vocab[i]]\n","    word_freq_j = word_window_freq[vocab[j]]\n","    # PMI = p(i,j) / (p(i)*p(j))\n","    pmi = log((count / num_window) /\n","              (word_freq_i * word_freq_j/(num_window * num_window)))\n","    if pmi <= 0:\n","        continue\n","    row.append(train_size + i)\n","    col.append(train_size + j)\n","    weight.append(pmi)"]},{"cell_type":"code","source":["row[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sVcsFwoxJ9Vm","executionInfo":{"status":"ok","timestamp":1663396482122,"user_tz":-480,"elapsed":284,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"ddc0dc66-caf2-4334-c438-992d5c3ea279"},"id":"sVcsFwoxJ9Vm","execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[8529, 12591, 10396, 12591, 10396]"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["col[:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-rMLgQqKDFz","executionInfo":{"status":"ok","timestamp":1663396496043,"user_tz":-480,"elapsed":288,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"b007bc4d-e162-45ab-ac19-d2f03410f11f"},"id":"Z-rMLgQqKDFz","execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[12591, 8529, 12591, 10396, 8529]"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","execution_count":13,"id":"8c7d1f4c","metadata":{"id":"8c7d1f4c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663396190879,"user_tz":-480,"elapsed":8,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"042dbea6-f23b-442b-9513-a15952f17ba7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of edges: 2432734\n"]}],"source":["print(\"Number of edges:\",len(row))"]},{"cell_type":"markdown","id":"16fc62fa","metadata":{"id":"16fc62fa"},"source":["## Creating word-document edges and calculate TF-IDF"]},{"cell_type":"code","execution_count":14,"id":"2171b9dc","metadata":{"id":"2171b9dc","executionInfo":{"status":"ok","timestamp":1663396192570,"user_tz":-480,"elapsed":1696,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}}},"outputs":[],"source":["# doc word frequency\n","doc_word_freq = defaultdict(lambda:0)\n","\n","for doc_id in document_ids:\n","    doc_words = doc_content_list[doc_id]\n","    words = doc_words.split()\n","    for word in words:\n","        word_id = word_id_map[word]\n","        doc_word_str = str(doc_id) + ',' + str(word_id)\n","        doc_word_freq[doc_word_str] += 1\n","\n","for doc_index in document_ids:\n","    doc_words = doc_content_list[doc_index]\n","    \n","    # avoid repeated calculation\n","    words = set(doc_words.split()) \n","    for word in words:\n","        word_index = word_id_map[word]\n","        key = str(doc_index) + ',' + str(word_index)\n","        freq = doc_word_freq[key]\n","        if doc_index < train_size:\n","            row.append(doc_index)\n","        else:\n","            row.append(doc_index + vocab_size)\n","        col.append(train_size + word_index)\n","        \n","        # TF-IDF as edge weight\n","        idf = log(1.0 * len(document_ids) /\n","                  word_doc_freq[vocab[word_index]])\n","        weight.append(freq * idf) # TF*IDF\n"]},{"cell_type":"code","execution_count":15,"id":"fcb4f685","metadata":{"id":"fcb4f685","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663396192571,"user_tz":-480,"elapsed":12,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"ffeaec3f-0b7a-41a5-c512-f13469dd56a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of edges: 2756404\n"]}],"source":["print(\"Number of edges:\",len(row))"]},{"cell_type":"markdown","id":"7ee785a4","metadata":{"id":"7ee785a4"},"source":["### Storing all data in `pyg_data`"]},{"cell_type":"code","execution_count":16,"id":"e2f27f35","metadata":{"id":"e2f27f35","executionInfo":{"status":"ok","timestamp":1663396193611,"user_tz":-480,"elapsed":597,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}}},"outputs":[],"source":["# nodes\n","node_size = train_size + vocab_size + test_size\n","pyg_data.num_nodes = node_size\n","\n","adj = sp.csr_matrix(\n","    (weight, (row, col)), shape=(node_size, node_size))\n","adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj) # symmetric\n","\n","from torch_geometric.utils import from_scipy_sparse_matrix\n","edge_index, edge_weight = from_scipy_sparse_matrix(adj)\n","\n","pyg_data.edge_index = edge_index.long()\n","pyg_data.edge_weight = edge_weight.float()"]},{"cell_type":"code","execution_count":17,"id":"b0b00bfb","metadata":{"id":"b0b00bfb","executionInfo":{"status":"ok","timestamp":1663396194061,"user_tz":-480,"elapsed":452,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}}},"outputs":[],"source":["# masks for training, testing\n","train_masks = torch.zeros(node_size).bool()\n","train_masks[train_ids] = 1\n","test_masks = torch.zeros(node_size).bool()\n","test_masks[test_ids+vocab_size] = 1 \n","\n","pyg_data.train_mask = train_masks\n","pyg_data.test_mask = test_masks\n","\n","# labels\n","pyg_data.num_classes = num_classes\n","targets = [torch.FloatTensor(train_target), torch.zeros(vocab_size), torch.FloatTensor(test_target)]\n","targets = torch.cat(targets,dim=0).long()\n","pyg_data.target = targets\n","assert targets.shape[0] == pyg_data.num_nodes\n","\n","# initial node feature\n","node_feature = torch.eye(pyg_data.num_nodes)\n","pyg_data.x = node_feature"]},{"cell_type":"code","execution_count":32,"id":"26be1bbd","metadata":{"id":"26be1bbd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663398941478,"user_tz":-480,"elapsed":272,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"3e192b18-8e66-40ca-93db-f81a319fef8d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Data(num_nodes=15362, edge_index=[2, 3080074], edge_weight=[3080074], train_mask=[15362], test_mask=[15362], num_classes=8, target=[15362], x=[15362, 15362])"]},"metadata":{},"execution_count":32}],"source":["pyg_data"]},{"cell_type":"code","source":["model = GCNConv(15362,8).to(device)"],"metadata":{"id":"Tnghzu4NKrlf","executionInfo":{"status":"ok","timestamp":1663396746331,"user_tz":-480,"elapsed":5,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}}},"id":"Tnghzu4NKrlf","execution_count":28,"outputs":[]},{"cell_type":"code","source":["model(pyg_data.x,pyg_data.edge_index,pyg_data.edge_weight).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-oTtPE0HK1aX","executionInfo":{"status":"ok","timestamp":1663396761262,"user_tz":-480,"elapsed":2,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"c1d3b090-156f-4906-c71d-e89230823258"},"id":"-oTtPE0HK1aX","execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([15362, 8])"]},"metadata":{},"execution_count":30}]},{"cell_type":"markdown","id":"501930b5","metadata":{"id":"501930b5"},"source":["## Practice: Training TextGCN model\n","So far, we prepare everything you need to train the TextGCN model. <br>\n","Please try to create a GCN model and perform the text classification as a node classification task.<br>"]},{"cell_type":"code","execution_count":48,"id":"10e720c4","metadata":{"id":"10e720c4","executionInfo":{"status":"ok","timestamp":1663399899156,"user_tz":-480,"elapsed":10,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}}},"outputs":[],"source":["from torch_geometric.nn import GCNConv\n","import torch.nn.functional as F\n","import torch.nn as nn\n","\n","class TextGCN(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels):\n","        super().__init__()\n","        ############################################################################\n","        # TODO: Your code here! \n","        # create your GCN models here\n","        # Note: the input and output dimension is defined by the input parameters in_channels and out_channels\n","        self.gcn1 = GCNConv(in_channels, hidden_channels)\n","        self.gcn2 = GCNConv(hidden_channels, out_channels)\n","        ############################################################################\n","\n","    def forward(self, x, edge_index, edge_weight):\n","        # x = None\n","        ############################################################################\n","        # TODO: Your code here!       \n","        # define your forward pass logic here\n","        x = self.gcn1(x, edge_index, edge_weight)\n","        x = torch.relu(x)\n","        x = self.gcn2(x, edge_index, edge_weight)\n","        ############################################################################\n","        return x"]},{"cell_type":"code","execution_count":49,"id":"2a66f4ac","metadata":{"id":"2a66f4ac","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1663399899157,"user_tz":-480,"elapsed":8,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"fd466744-ecc3-43e0-c1d1-2fdc8a1747ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["TextGCN(\n","  (gcn1): GCNConv(15362, 64)\n","  (gcn2): GCNConv(64, 8)\n",")\n"]}],"source":["# model configurations\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","dim = 64 \n","model = TextGCN(pyg_data.x.shape[1], dim, 8).to(device)\n","optimizer = torch.optim.Adam(model.parameters())\n","criterion = nn.CrossEntropyLoss(reduction=\"none\")\n","############################################################################\n","# TODO: Your code here!  \n","# setup the model, optimizer here\n","\n","############################################################################\n","print(model)"]},{"cell_type":"code","execution_count":38,"id":"f6158177","metadata":{"id":"f6158177","executionInfo":{"status":"ok","timestamp":1663399151056,"user_tz":-480,"elapsed":1,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}}},"outputs":[],"source":["# map data to GPU device\n","pyg_data.x = pyg_data.x.to(device)\n","pyg_data.edge_index = pyg_data.edge_index.to(device)\n","pyg_data.edge_weight = pyg_data.edge_weight.to(device)\n","pyg_data.target = pyg_data.target.to(device)"]},{"cell_type":"code","execution_count":39,"id":"b3bfde67","metadata":{"id":"b3bfde67","colab":{"base_uri":"https://localhost:8080/","height":385},"executionInfo":{"status":"error","timestamp":1663399151498,"user_tz":-480,"elapsed":8,"user":{"displayName":"Yu-Che Tsai","userId":"11097797349614937936"}},"outputId":"46faab0d-2a6e-445c-8510-bcb8887a08c1"},"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-39-eb9e9e1c2ec7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpyg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpyg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpyg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpyg_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-33-09f0ede368fa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: forward() missing 1 required positional argument: 'edge_index'"]}],"source":["for epoch in range(200):\n","    logits = model(pyg_data.x, pyg_data.edge_index, pyg_data.edge_weight)\n","    loss = criterion(logits, pyg_data.target)[pyg_data.train_mask]\n","    loss = loss.mean()    \n","    \n","    # Backward and optimize\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    \n","    # evaluation\n","    # train_accuracy = None\n","    # test_accuracy = None\n","    ############################################################################\n","    # TODO: Your code here!  \n","    # calculate the train/test accuracy\n","    \n","    ############################################################################\n","    # print(f\"Train Accuracy:{train_accuracy:.4f} | Test Accuracy:{test_accuracy:.4f}\")"]},{"cell_type":"markdown","id":"26a90a56","metadata":{"id":"26a90a56"},"source":["## Additional questions\n","If you already finish the above exercise, try to answer the follwing questions!\n","* How many GCN layers achieves the best performance?\n","* Does the window size effect the performance? What happens if we increase or decrease the window size?\n","* What are the limitations of TextGCN?"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[],"collapsed_sections":[]},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"0a82691357244784b013f12170604a65":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b1803b8d62a44f1697135918c073a1c9","IPY_MODEL_a45319a11afa471eb444b1aaeca98082","IPY_MODEL_c88174bbd9a54ae3887f9a44c9fc00b1"],"layout":"IPY_MODEL_497d2a652f4348fb89399f28b10aee85"}},"b1803b8d62a44f1697135918c073a1c9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1eee6e4b846944928a9463141fd3cc8f","placeholder":"​","style":"IPY_MODEL_c9cba94290e84baea9563b4c207f0b59","value":"100%"}},"a45319a11afa471eb444b1aaeca98082":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f45a57d5a7c142e48f178b02780a9d3d","max":400703,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f952c8d4c3054bd8a1dc26492935e90f","value":400703}},"c88174bbd9a54ae3887f9a44c9fc00b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_991f6fa9476741809b4ccf5be46a681b","placeholder":"​","style":"IPY_MODEL_87be341abfdc4b01a9dc1da289eda1df","value":" 400703/400703 [01:24&lt;00:00, 4714.59it/s]"}},"497d2a652f4348fb89399f28b10aee85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1eee6e4b846944928a9463141fd3cc8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9cba94290e84baea9563b4c207f0b59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f45a57d5a7c142e48f178b02780a9d3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f952c8d4c3054bd8a1dc26492935e90f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"991f6fa9476741809b4ccf5be46a681b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87be341abfdc4b01a9dc1da289eda1df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}